{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data_dir = '/data/pablo/RNAdeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/pmonteagudo/workspace/RNAdeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dir = '/data/parastou/RNAdeg/data/AllRNA/'\n",
    "source_dir = os.path.join(project_data_dir, 'data/ChIP')\n",
    "#source_dir = os.path.join(project_data_dir, 'data/sequencing_new/ChIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample_names(names, col_name=None):\n",
    "    \n",
    "    ## select col_name\n",
    "    if col_name is None:\n",
    "        if isinstance(names, pd.DataFrame) and names.shape[0] == 1:\n",
    "            col_name = names.columns[0]\n",
    "        else:\n",
    "            col_name = \"sample_name\"\n",
    "    \n",
    "    ## get dataframe\n",
    "    if not isinstance(names, pd.DataFrame):\n",
    "\n",
    "        ## create dataframe from list\n",
    "        df = pd.DataFrame(data = names, columns=[col_name])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ## already a dataframe\n",
    "        df = names\n",
    "        \n",
    "    ## sort dataframe by col_name\n",
    "    df = df.sort_values(by=[col_name]).reset_index(drop=True)\n",
    "        \n",
    "    ## get sample's prefix\n",
    "    df[\"prefix\"] = df[col_name].map(lambda x: x.split(\".\")[0])\n",
    "    \n",
    "    ## check for \"duplicated\" files (share same prefix) within the same directory.\n",
    "    ## one should be careful and wonder why is that?\n",
    "    n_samples = df.shape[0]\n",
    "    df = df[~df.duplicated(subset=\"prefix\", keep=False)] ## remove entries with duplicated prefix\n",
    "    \n",
    "    #assert(n_samples == df.shape[0])\n",
    "    if n_samples != df.shape[0]:\n",
    "        print(\"\\n{}\".format(\"-\"*99))\n",
    "        print(\" Warning! Duplicated files (share same prefix) within the same directory. \\n Will be ignored for now!\")        \n",
    "        print(\"{}\\n\".format(\"-\"*99))\n",
    "\n",
    "    #print(\"Number of files in `{}`: {}\".format(col_name, df.shape[0]) )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Investigate Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. __Load `valid_samples.txt` file__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_samples_file = os.path.join(source_dir, 'valid_samples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid samples (as given by Parastou): 22\n"
     ]
    }
   ],
   "source": [
    "valid_samples = pd.read_csv(valid_samples_file, header=None, names = [\"valid_sample\"])\n",
    "valid_samples = process_sample_names(valid_samples, col_name=\"valid_sample\")\n",
    "print(\"Number of valid samples (as given by Parastou): {}\".format(valid_samples.shape[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. __Load `remote_RNA_file_names.txt` file__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_samples_file = os.path.join(source_dir, 'remote_ChIP_file_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remote samples (as present in /data/cryohalic01/home/ag_halic/share/Conny/fastq_for_Stefan_RNAdeg): 8\n"
     ]
    }
   ],
   "source": [
    "remote_samples = pd.read_csv(remote_samples_file, header=None, names = [\"remote_sample\"])\n",
    "remote_samples = process_sample_names(remote_samples, col_name=\"remote_sample\")\n",
    "remote_dir = \"/data/cryohalic01/home/ag_halic/share/Conny/fastq_for_Stefan_RNAdeg\"\n",
    "print(\"Number of remote samples (as present in {}): {}\".format(remote_dir, remote_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remote_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. __Check in `source_dir` for sample files ('.bz2', '.fastq', '.fastqsanger')__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sample files in `source_dir` (/data/pablo/RNAdeg/data/ChIP): 27\n"
     ]
    }
   ],
   "source": [
    "file_formats = ('.bz2', '.fastq', '.fastqsanger')\n",
    "source_samples_names = [ff for ff in os.listdir(source_dir) if ff.endswith(file_formats)]\n",
    "#source_samples_names = pd.read_csv(source_dir + 'sample_names.txt', header=None, names = [\"source_sample\"])\n",
    "source_samples = process_sample_names(source_samples_names, col_name=\"source_sample\")\n",
    "print(\"Number of sample files in `source_dir` ({}): {}\".format(source_dir, source_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This means there are __\"duplicated\" files__ (share same prefix) within the same directory. One should be careful and wonder __why is that__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(source_samples_names) == source_samples.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_files = sorted(list(set(source_samples_names).difference(source_samples.source_sample)))\n",
    "duplicated_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. __Merge (Samples) DataFrames: [`source_dir`, `valid_samples.txt`, `remote_RNA_file_names.txt`]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [valid_samples, remote_samples, source_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['prefix'], how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = df_merged.sort_values(\"prefix\").reset_index(drop=True)\n",
    "df_merged = df_merged[[\"prefix\", \"valid_sample\", \"remote_sample\", \"source_sample\"]]\n",
    "df_merged = df_merged.set_index(\"prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Compare  `source_dir` vs `valid_samples.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = [\"valid_sample\", \"source_sample\"]\n",
    "source_vs_valid_samples = df_merged[select_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are samples that are either __not valid__ or __missing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vs_valid_samples = source_vs_valid_samples[source_vs_valid_samples[\"valid_sample\"].isna() != source_vs_valid_samples[\"source_sample\"].isna()]\n",
    "len(source_vs_valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Not valid__ samples (present in `source_dir` but not in `valid_samples.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NOT valid samples: 5\n"
     ]
    }
   ],
   "source": [
    "not_valid_samples = source_vs_valid_samples[source_vs_valid_samples.valid_sample.isna()]\n",
    "print(\"Number of NOT valid samples:\", len(not_valid_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_valid_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Missing__ samples (present in `valid_samples.txt` but not in `source_dir`): Ideally this should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing samples (e.g. valid but are not in the `source_dir`: 0\n"
     ]
    }
   ],
   "source": [
    "missing_samples = source_vs_valid_samples[source_vs_valid_samples.source_sample.isna()]\n",
    "print(\"Number of missing samples (e.g. valid but are not in the `source_dir`:\", len(missing_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples used in Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ignore samples that are not valid, also ignore samples that give errors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_files = set([\"302_S2RIP_2\", \"63_RNA_pA_3\"])\n",
    "## union\n",
    "ignore_files = set(not_valid_samples.index | ignore_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples that will be ignored: 7\n"
     ]
    }
   ],
   "source": [
    "ignore_files = sorted([ff + \".\"  for ff in ignore_files])\n",
    "print(\"Number of samples that will be ignored:\", len(ignore_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Samples used in Analysis are present in `source_dir` and `valid_samples.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples that will be analyzed: 22\n"
     ]
    }
   ],
   "source": [
    "prefix_files = df_merged[(~df_merged.source_sample.isna()) & (~df_merged.valid_sample.isna())].index.tolist()\n",
    "print(\"Total number of samples that will be analyzed:\", len(prefix_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefix_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (heterochromatin)",
   "language": "python",
   "name": "heterochromatin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
