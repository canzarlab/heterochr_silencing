{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_data_dir = '/data/pablo/RNAdeg' # algbio /data\n",
    "project_data_dir = '/gcm-lfs1/pablo/data/RNAdeg' # algbio /gcm-lfs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = '/home/pmonteagudo/workspace/RNAdeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = 'RNA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_dir = '/data/parastou/RNAdeg/data/AllRNA/'\n",
    "#source_dir = os.path.join(project_data_dir, 'data/RNA')\n",
    "#source_dir = os.path.join(project_data_dir, 'data/sequencing_new/RNA')\n",
    "source_dir = os.path.join(project_data_dir, 'data', data_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_sample_names(names, col_name=None):\n",
    "    \n",
    "    ## select col_name\n",
    "    if col_name is None:\n",
    "        if isinstance(names, pd.DataFrame) and names.shape[0] == 1:\n",
    "            col_name = names.columns[0]\n",
    "        else:\n",
    "            col_name = \"sample_name\"\n",
    "    \n",
    "    ## get dataframe\n",
    "    if not isinstance(names, pd.DataFrame):\n",
    "\n",
    "        ## create dataframe from list\n",
    "        df = pd.DataFrame(data = names, columns=[col_name])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        ## already a dataframe\n",
    "        df = names\n",
    "        \n",
    "    ## sort dataframe by col_name\n",
    "    df = df.sort_values(by=[col_name]).reset_index(drop=True)\n",
    "        \n",
    "    ## get sample's prefix\n",
    "    df[\"prefix\"] = df[col_name].map(lambda x: x.split(\".\")[0])\n",
    "    \n",
    "    ## check for \"duplicated\" files (share same prefix) within the same directory.\n",
    "    ## one should be careful and wonder why is that?\n",
    "    n_samples = df.shape[0]\n",
    "    df = df[~df.duplicated(subset=\"prefix\", keep=False)] ## remove entries with duplicated prefix\n",
    "    \n",
    "    #assert(n_samples == df.shape[0])\n",
    "    if n_samples != df.shape[0]:\n",
    "        print(\"\\n{}\".format(\"-\"*99))\n",
    "        print(\" Warning! Duplicated files (share same prefix) within the same directory. \\n Will be ignored for now!\")        \n",
    "        print(\"{}\\n\".format(\"-\"*99))\n",
    "\n",
    "    #print(\"Number of files in `{}`: {}\".format(col_name, df.shape[0]) )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Investigate Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. __Load `valid_samples.txt` file__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_samples_file = os.path.join(source_dir, 'valid_samples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid samples (as given by Parastou): 54\n"
     ]
    }
   ],
   "source": [
    "valid_samples = pd.read_csv(valid_samples_file, header=None, names = [\"valid_sample\"])\n",
    "valid_samples = process_sample_names(valid_samples, col_name=\"valid_sample\")\n",
    "print(\"Number of valid samples (as given by Parastou): {}\".format(valid_samples.shape[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#valid_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. __Load `remote_RNA_file_names.txt` file__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_samples_file = os.path.join(source_dir, 'remote_RNA_file_names.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of remote samples (as present in /data/cryohalic01/home/ag_halic/share/Conny/fastq_for_Stefan_RNAdeg): 32\n"
     ]
    }
   ],
   "source": [
    "remote_samples = pd.read_csv(remote_samples_file, header=None, names = [\"remote_sample\"])\n",
    "remote_samples = process_sample_names(remote_samples, col_name=\"remote_sample\")\n",
    "remote_dir = \"/data/cryohalic01/home/ag_halic/share/Conny/fastq_for_Stefan_RNAdeg\"\n",
    "print(\"Number of remote samples (as present in {}): {}\".format(remote_dir, remote_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remote_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. __Check in `source_dir` for sample files ('.bz2', '.fastq', '.fastqsanger')__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------------------------------------\n",
      " Warning! Duplicated files (share same prefix) within the same directory. \n",
      " Will be ignored for now!\n",
      "---------------------------------------------------------------------------------------------------\n",
      "\n",
      "Number of sample files in `source_dir` (/data/pablo/RNAdeg/data/RNA): 66\n"
     ]
    }
   ],
   "source": [
    "file_formats = ('.bz2', '.fastq', '.fastqsanger')\n",
    "source_samples_names = [ff for ff in os.listdir(source_dir) if ff.endswith(file_formats)]\n",
    "#source_samples_names = pd.read_csv(source_dir + 'sample_names.txt', header=None, names = [\"source_sample\"])\n",
    "source_samples = process_sample_names(source_samples_names, col_name=\"source_sample\")\n",
    "print(\"Number of sample files in `source_dir` ({}): {}\".format(source_dir, source_samples.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This means there are __\"duplicated\" files__ (share same prefix) within the same directory. One should be careful and wonder __why is that__?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-19ac9dfb49d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_samples_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msource_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert(len(source_samples_names) == source_samples.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['63_RNA_pA_3.fastq', '63_RNA_pA_3.ztr.fastq']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicated_files = sorted(list(set(source_samples_names).difference(source_samples.source_sample)))\n",
    "duplicated_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. __Merge (Samples) DataFrames: [`source_dir`, `valid_samples.txt`, `remote_RNA_file_names.txt`]__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [valid_samples, remote_samples, source_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['prefix'], how='outer'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort\n",
    "df_merged = df_merged.sort_values(\"prefix\").reset_index(drop=True)\n",
    "# shuffle columns\n",
    "df_merged = df_merged[[\"prefix\", \"valid_sample\", \"remote_sample\", \"source_sample\"]]\n",
    "# set \"prefix\" as index\n",
    "df_merged = df_merged.set_index(\"prefix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Compare  `source_dir` vs `valid_samples.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = [\"valid_sample\", \"source_sample\"]\n",
    "source_vs_valid_samples = df_merged[select_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are samples that are either __not valid__ or __missing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vs_valid_samples = source_vs_valid_samples[source_vs_valid_samples[\"valid_sample\"].isna() != source_vs_valid_samples[\"source_sample\"].isna()]\n",
    "len(source_vs_valid_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Not valid__ samples (present in `source_dir` but not in `valid_samples.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NOT valid samples: 20\n"
     ]
    }
   ],
   "source": [
    "not_valid_samples = source_vs_valid_samples[source_vs_valid_samples.valid_sample.isna()]\n",
    "print(\"Number of NOT valid samples:\", len(not_valid_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not_valid_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Missing__ samples (present in `valid_samples.txt` but not in `source_dir`): Ideally this should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing samples (e.g. valid but are not in the `source_dir`: 8\n"
     ]
    }
   ],
   "source": [
    "missing_samples = source_vs_valid_samples[source_vs_valid_samples.source_sample.isna()]\n",
    "print(\"Number of missing samples (e.g. valid but are not in the `source_dir`:\", len(missing_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We see that some of the `valid_sample`s (7) seem to be missing an \"A\" at the end.\n",
    "- (1) `valid_sample` \"302_S2RIP_2\" is also missing but this the sample that we ignore because is raising an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Compare  `source_dir` vs `remote_RNA_file_names.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_cols = [\"source_sample\", \"remote_sample\"]\n",
    "source_vs_remote_samples = df_merged[select_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are samples that are either present in __missing from source_dir__ or __missing from remote_dir__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_vs_remote_samples = source_vs_remote_samples[source_vs_remote_samples[\"source_sample\"].isna() != source_vs_remote_samples[\"remote_sample\"].isna()]\n",
    "len(source_vs_remote_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source_vs_remote_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Missing from remote_dir__ samples (present in `source_dir` but not in `remote_RNA_file_names.txt`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples missing in the source_dir: 35\n"
     ]
    }
   ],
   "source": [
    "missing_from_remote = source_vs_remote_samples[source_vs_remote_samples.remote_sample.isna()]\n",
    "print(\"Number of samples missing in the source_dir:\", len(missing_from_remote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1167_S5RIP_2',\n",
       " '283_RNA_pA_4',\n",
       " '301_RNA_pA_3',\n",
       " '301_S2RIP_3',\n",
       " '302_S2RIP_3',\n",
       " '324S2RIP_1',\n",
       " '324_RNA_pA_3',\n",
       " '324_S2RIP_3',\n",
       " '491S2RIP_1',\n",
       " '491_S2RIP_3',\n",
       " '504S2RIP_1',\n",
       " '504S2RIP_2',\n",
       " '504_RNA_pA_1',\n",
       " '504_RNA_pA_2',\n",
       " '530S2RIP_1',\n",
       " '530S2RIP_2',\n",
       " '530_RNA_pA_1',\n",
       " '530_RNA_pA_2',\n",
       " '591_S5RIP_1',\n",
       " '63',\n",
       " '638S2RIP_1',\n",
       " '638S2RIP_2',\n",
       " '638_RNA_pA_1',\n",
       " '638_RNA_pA_2',\n",
       " '63_RIPS5P',\n",
       " '63_RNA_pA_3',\n",
       " '63_RNA_pA_4',\n",
       " '63_S2PRIP',\n",
       " '63_S2Ph_RIP',\n",
       " '63_S2RIP_2',\n",
       " '63_S5Ph_RIP',\n",
       " '65',\n",
       " '80S2RIP_1',\n",
       " '80S2RIP_2',\n",
       " '80pARNA_2']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_from_remote.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Missing from source_dir__ samples (present in `remote_RNA_file_names.txt` but not in `source_dir`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing samples (e.g. valid but are not in the `source_dir`: 1\n"
     ]
    }
   ],
   "source": [
    "missing_from_source = source_vs_remote_samples[source_vs_remote_samples.source_sample.isna()]\n",
    "print(\"Number of missing samples (e.g. valid but are not in the `source_dir`:\", len(missing_from_source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (1) `remote_sample` \"302_S2RIP_2\" is missing but this the sample that we ignore because is raising an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_sample</th>\n",
       "      <th>remote_sample</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prefix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302_S2RIP_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>302_S2RIP_2.fastq.bz2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            source_sample          remote_sample\n",
       "prefix                                          \n",
       "302_S2RIP_2           NaN  302_S2RIP_2.fastq.bz2"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_from_source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples used in Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Errors__:\n",
    "-  302_S2RIP_2.fastq\n",
    "-  63_RNA_pA_3.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ignore samples that are not valid, also ignore samples that give errors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore_files = set([\"302_S2RIP_2\", \"63_RNA_pA_3\"])\n",
    "ignore_files = set([\"302_S2RIP_2\"]) ## we already removed the file from directory\n",
    "## union\n",
    "ignore_files = set(not_valid_samples.index | ignore_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples that will be ignored: 22\n"
     ]
    }
   ],
   "source": [
    "ignore_files = sorted([ff + \".\"  for ff in ignore_files])\n",
    "print(\"Number of samples that will be ignored:\", len(ignore_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Samples used in Analysis are present in `source_dir` and `valid_samples.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of samples that will be analyzed: 46\n"
     ]
    }
   ],
   "source": [
    "prefix_files = df_merged[(~df_merged.source_sample.isna()) & (~df_merged.valid_sample.isna())].index.tolist()\n",
    "print(\"Total number of samples that will be analyzed:\", len(prefix_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prefix_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (heterochromatin)",
   "language": "python",
   "name": "heterochromatin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
